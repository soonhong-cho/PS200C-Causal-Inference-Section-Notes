---
title: '200C Annan and Blattman (2010) Matching Example'
author: 'Chad Hazlett, Aaron Rudkin, and Soonhong Cho'
date: "April 28, 2022"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.align = 'center')
```
\newcommand{\y}{\mathbf{y}}
\newcommand{\X}{\mathbf{X}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\independent}{\perp\!\!\!\perp}





```{r message=FALSE}
library(foreign) # Loading normally unsupported file formats
library(tidyverse)
library(Matching) # Finding matches
library(ebal) # Entropy balancing weights
library(cobalt) # Easy love plots.

dat <- read.csv("BlattmanAnnan.csv")

# Let's take a look at the top few rows of the data frame:
head(dat)
```

# MATCHING
## Check the covariate balance in the unmatched dataset. 

First, before reporting actual balance statistics let's take a look at what seems to predict treatment status. This implies a regression where the dependent variable is treatment status and the predictors are every other covariate we can fit.

What are some of the methods we can predict balance? We could try a multiple regression setting:

```{r}
# We keep covariates to use going forward
covariates <- c("age", "fthr_ed", "mthr_ed", "hh_size96", "orphan96", "C_ach",
                "C_akw", "C_ata", "C_kma", "C_oro", "C_pad", "C_paj", "C_pal")

# We can specify a formula using `paste` function for use later
balance_formula <- as.formula(paste("abd ~ ", paste(covariates, collapse=" + ")))
balance_formula

summary(lm(balance_formula, data=dat))
```

We could try a t-test and KS test:

```{r}
t.test(dat$age ~ dat$abd, var.equal=FALSE)
ks.test(x=dat[dat$abd==1, ]$age, 
        y=dat[dat$abd==0, ]$age)
```

We could plot the eCDF of each covariate between treatment and control,

```{r}
library(reshape2) #for `melt` function
dat %>% dplyr::select(abd, all_of(covariates)) %>%
  mutate(abd = as_factor(ifelse(abd==1, "Treaed", "Control"))) %>% 
  melt(all_of(covariates), id.vars = "abd") %>% #make it "long format" for plotting
  ggplot(aes(x = value)) +
  stat_ecdf(aes(col = as_factor(abd)), alpha = .4) +
  facet_wrap(~ variable, scales = "free") +
  labs(title=paste0("Empirical CDF of Covariates by Treatment Status"), 
       y="Quantile (0 - 1)", col = "Treatment") +
  theme_minimal() +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

We could also plot the PDF of each covariate between treatment and control:

```{r, fig.width=6, fig.height=4}
dat %>% dplyr::select(abd, all_of(covariates)) %>%
  mutate(abd = as_factor(ifelse(abd==1, "Treaed", "Control"))) %>% 
  melt(all_of(covariates), id.vars = "abd") %>% #make it "long format" for plotting
  ggplot(aes(x = value)) +
  geom_density(aes(col = as_factor(abd)), alpha = 0.4) +
  facet_wrap(~ variable, scales = "free") +
  labs(title=paste0("PDF of Covariates by Treatment Status"), 
       y="Density",col = "Treatment") +
  labs(col = "Treatment") +
  theme_minimal() +
  theme(axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

But we can automate this process using `MatchBalance` function in `Matching` package:

```{r}
library(Matching)

# First argument: A formula describing the balance we're checking; the left
# hand side is the dependent variable (in our case, treatment status). The 
# right hand side is all the variables you want to check balance on.

# nboots because Matching uses bootstrapping to get SEs on the KS test.
# How many boots? Default is 500, but make it way higher.

mb <- MatchBalance(balance_formula, data=dat, nboots=10000)
```

There are two issues here. First, Matching does not obey R convention -- rather than quietly returning the data of interest into an object for future printing, Matching will automatically print a ton of output. Second, the output is ugly. There are a variety of packages you can use to make it not ugly, one of which is `ebal`. Let's use `baltest.collect` from `ebal`.

```{r}
library(ebal)
# baltest.collect takes three arguments; first, the Matching object.
# Second, which variables do you care about balance on? (Why does this not 
# default to every right-hand side variable? Who knows.) How do we specify the
# variable names? As a vector of character strings -- annoying! Let's quickly
# pop them out of the formula from before:
covariates
# Why do we do [-1]? The first variable is the treatment status, and we don't
# need "balance" on that.

# Third, do you want to see balance before any Matching attempt, or after?
# We want to see before, so we use after = FALSE
balance_test <- baltest.collect(mb,
                        var.names = covariates,
                        after = FALSE)

# balance_test includes a bunch of stuff we don't care about. Let's discard down:
balance_test <- balance_test[, c("mean.Tr", "mean.Co", "T pval", "KS pval")]

# Let's make a nice kable table:
library(knitr)
library(kableExtra) #for aesthetics
balance_test %>%
  kable(booktabs = T, digits=3, align = rep('c', 4),
        col.names = c("Treatment Mean", "Control Mean", "T p-value", "Ks p-value")) %>% 
  kable_styling(full_width = F, position = "center")
```

What do we think of this balance?

# Matching

Let's do some matching. Let's try to extract the ATT -- so we'll use our real treatment observations, matched control observations, and discard the rest. We'll do a simple match; one match per treated unit. And we'll use replacement (so the same control unit can be picked as a match for more than one treated unit)

We also need to specify which variables we want to match on exactly. First we'll subset to the variables we care about, and then we'll take a peek at those variable to see whether they're likely to need exact matches:
```{r}
outcome <- dat$educ
treated <- dat$abd
X <- dat[, covariates]
str(X)
```

We don't have any variables that are obviously "continuous", but a few look to me like they can take many possible values: `age` and `hh_size96`. Let's just briefly confirm that:

```{r}
length(unique(X$age))
length(unique(X$hh_size96))
```

We've only got 741 observations so with 23 possible values of household size and 17 of age we probably don't want exact matching for those. The rest all look like they're binary or only take a few values, so for them we'll do exact matching.

```{r}
exact_matches <- ifelse(colnames(X) %in% c("age", "hh_size96"), FALSE, TRUE)
```

How does `ifelse` work? It takes three arguments and outputs a vector. The first argument is a statement to evaluate. We're going to map every single column name, and check for each of them are they "in" the vector `c("age", "hh_size96")`. If they are, use the value `FALSE` for that item in the vector. If they are not, use the value `TRUE` for that item in the vector.

Now let's do the matching.

```{r}
match_model_1 <- Match(Y = outcome,
                       Tr = treated,
                       X = X,
                       M = 1,
                       exact = exact_matches,
                       estimand = "ATT")
```

What are the arguments here? Well, it's obvious you need `Y` to estimate a treatment effect. It's obvious you need `Tr` so it knows which units are treated and which are controlled. `X` is the covariates to match on. `M` tells you how many matches you want for each treatment unit. `exact` says, for each covariate, if you want an exact match or not. `estimand` tells `Matching` your estimand: in our case we want to keep the real treated units and find matching control units.

We can also easily do bias adjustment:

```{r}
match_model_2 <- Match(Y = outcome,
                       Tr = treated,
                       X = X,
                       M = 1, # one-to-one matching
                       exact = exact_matches,
                       estimand = "ATT",
                       BiasAdjust = TRUE)
```

Bias Adjustment compensates for the fact that since we can't find exact matches, the effect size will be a little skewed (imagine there's a relationship between X and Y, but the Xs of treated units are all slightly higher than the Xs of the control units they are matched with -- or vice versa -- wouldn't this bias our effect estimate?)

Let's now check what `Matching` actually gives us:


```{r}
ls(match_model_1)
```

This tells us what is contained in the `Match` object; We see a few we might like to check out:

```{r}
match_model_1$est
match_model_1$se # SEs from Abadie-Imbens
```

We can also check what got matched with what:

```{r}
match_model_1$orig.nobs #number of units in original data
length(match_model_1$index.treated) #number of treated units in matched data
length(match_model_1$index.control) #number of control units in matched data
length(match_model_1$index.dropped) #number of dropped units during matching
length(unique(match_model_1$index.control)) #number of unique control units (some duplicates!)
```

We can set the number of matched controls per treated, using `M` option. How many control matches do we have to include? We have this trade-off: small $M$ (e.g., one-to-one matching) means small matched-sample sizes from which we estimate our quantity of interest, whereas large $M$ may give more bad matches (since we allow for worse matches to be included).

As can be seen below, we increased the number of matched control units by 302 compared to one-to-one match ($M=1$), but only 15 more unique controls used. It suggests that by setting `M=2`, we allowed for more bad 

```{r}
match_model_3 <- Match(Y = outcome,
                       Tr = treated,
                       X = X,
                       M = 2, #how many control units we match to each treatment unit: now 2 instead of 1
                       exact = exact_matches,
                       estimand = "ATT",
                       BiasAdjust = TRUE)

length(match_model_3$index.control) - length(match_model_1$index.control)
length(unique(match_model_3$index.control)) - length(unique(match_model_1$index.control))
```


And with the bias-adjusted estimates:
```{r}
match_model_2$est
match_model_2$se
```

Compare to "naive" estimate:

```{r}
summary(lm(educ ~ abd, data = dat))
```

## Balance After Matching
Normally, before you even look at results you'd examine balance post-matching. What we're trying to do here is make sure that the Matching process actually resulted in good balance. And we can include variables that we didn't match on, if we want.

Note, you can check balance on things that weren't matched on to make sure they got balanced too. 

```{r}
match_balance_after <- MatchBalance(match.out = match_model_1,
                                    formul = balance_formula,
                                    data = dat,
                                    print.level = 0,
                                    nboots = 10000)

balance_test_after <- baltest.collect(match_balance_after,
                                      var.names = covariates,
                                      after = TRUE)[, c("mean.Tr", "mean.Co",
                                                        "T pval", "KS pval")]

balance_test_after %>%
  kable(booktabs = T, digits=3, align = rep('c', 4),
        col.names = c("Treatment Mean", "Control Mean", "T p-value", "Ks p-value")) %>% 
  kable_styling(full_width = F, position = "center")
```


# Balance with Covariate-Balancing Weights

Instead of choosing a 1-to-1 match, we could choose weights on the control units in order to ensure that the weighted average of each $X$ for the controls equals the unweighted average among the treated. We could similarly get weighted averages for other numbered moments ($X^2$, $X^3$, etc.) This would give us exact balance on those moments.

We can do this with `ebal`:

```{r}
library(ebal)

# ebal needs us to remove one of the fixed effect dummies.
X_ebal <- X[, -13]
variable_names_ebal <- covariates[-13]

ebal_model <- ebalance(treated, X=X_ebal)
```

A quirk of `ebal` is that it returns a weight vector for only the control units, not the treated units. Which means that if we need a weight vector for, say, a weighted regression, we need to fill in those units. We do this by creating a vector of 1s with length equal to the number of the observations, and then override the control observations with the weights from `ebal`.

```{r}
# Make the vector of 1 weights:
ebal_weights <- rep(1, length(outcome))

# Now override the control weights:
ebal_weights[treated == 0] <- ebal_model$w
```

Now let's use these weights with `MatchBalance`

```{r}
ebal_balance <- MatchBalance(treated ~ as.matrix(X),
                             weights = ebal_weights,
                             print.level = 0,
                             nboots = 10000)

# Another weird quirk: we use after = FALSE, because we're not using MatchBalance
# to do the matching, we're just using the weights from ebal.
ebal_table <- baltest.collect(matchbal.out = ebal_balance,
                              var.names = colnames(X),
                              after = FALSE)[, c("mean.Tr", "mean.Co", 
                                                 "T pval", "KS pval")]

# Now output the table
bind_cols(balance_test, ebal_table) %>% 
  kable(booktabs = T, digits=3, align = rep('c', 8),
        col.names = rep(c("Treatment Mean", "Control Mean", "T p-value", "Ks p-value"), 2)) %>% 
  kable_styling(full_width = F, position = "center")
```

Another quirk (this is starting to get frustrating) -- the KS test p-values are incorrect when `MatchBalance` is used with weights. 

We can plot the standardized imbalance (and the subsequent balance) using the `love.plot` command in the `cobalt` package. `cobalt` is designed to work with the output from a wide variety of matching and weighting packages.

```{r}
library(cobalt)

# bal.tab() is a function which takes as arguments:
# ebal <-- an ebalance object (in our case, ebal_model)
# treat <-- a vector of treatment statuses
# covs <-- a matrix or data frame of Xes.
love.plot(bal.tab(x = ebal_model,
                  treat = treated,
                  covs = X_ebal), 
          threshold = 0.1, theme=theme_bw())
```

Nice looking plot, almost no code. And as we see, `ebal` produces exact moment matching, ensuring equal means across groups (note: it might do this by putting an extremely high weight on one or more of the observations). Let's just quickly check the summary stats of our weights:

```{r}
summary(ebal_weights)
```

The maximum weight doesn't seem too bad here, and fewer than a quarter of observations had weights much above 1.

# Propensity Scores

Another approach, as we saw in the previous week, is that we can estimate propensity scores for treatment. We can either match units on propensity score (look for control units with similar propensity scores to the treatment), or we can use the propensity scores to generate IPW weights and weight on them. First, let's get the scores using logistic regression.

```{r}
logit_fit <- glm(balance_formula, data = dat, family = binomial(link = logit))

# Extract these using predicted probabilities or with the direct fit object:
pi.out <- logit_fit$fitted.values

# Plot
ggplot(tibble(ps = pi.out, treatment = as_factor(ifelse(dat$abd==1, "Treated", "Control"))),
       aes(x=ps, col=treatment)) +
  geom_density() +
  labs(title="Distribution of propensity scores", y="Density", x="Propensity Score") +
  xlim(c(0,1)) +
  theme_minimal()
```

We can see that these distributions do not look quite the same. Your first intuition is likely to say "well, the treated look like they're more likely to take the treatment than the control units, isn't that normal?". But this is a sign of imbalance on its own. What we'd instead like is a sense that units, no matter what their propensity score, are in balanced proportions in the treated and control groups.

So, we're going to use our two methods. First, let's use `Match` to calculate the ATT with propensity score as the covariate:

```{r}
p_score_match <- Match(Y = outcome,
                       Tr = treated,
                       X = pi.out,
                       M = 1,
                       estimand = "ATT")
summary(p_score_match)
```

And checking the balance:
```{r}
p_score_match_balance <- MatchBalance(match.out = p_score_match,
                                      formul = balance_formula,
                                      data = dat,
                                      print.level = 0)

balance_table_ps_match <- baltest.collect(p_score_match_balance,
                                          var.names = covariates,
                                          after = TRUE)[,
                                                        c("mean.Tr", "mean.Co",
                                                          "T pval", "KS pval")]

balance_table_ps_match %>% 
  kable(booktabs = T, digits=3, align = rep('c', 4),
        col.names = c("Treatment Mean", "Control Mean", "T p-value", "Ks p-value")) %>% 
  kable_styling(full_width = F, position = "center")
```

Final alternative; using stabilized inverse propensity score weights.

```{r}
probability_treated <- mean(treated)
IPW <- ifelse(treated==1, probability_treated/pi.out, (1 - probability_treated)/(1 - pi.out))

ggplot(as_tibble(IPW), aes(x=value)) +
  geom_density() + geom_vline(xintercept=1, linetype="dashed", col="gray") +
  labs(title = "Distribution of IPW", x="IPW") + xlim(c(0, 3.5)) + theme_minimal()
```

See how distribution of propensity scores has changed:

```{r}
plot_df <- tibble(ps = pi.out, treatment = as_factor(ifelse(dat$abd==1, "Treated", "Control")), ipw = IPW) %>% 
  group_by(treatment) %>% 
  mutate(weight = ipw/sum(ipw))

ggplot(plot_df, aes(x=ps, col=treatment)) +
  geom_density(aes(weight=weight)) +
  labs(title="Distribution of propensity scores: Weighted", y="Density", x="Propensity Score") +
  xlim(c(0,1)) +
  theme_minimal()
```

Using IPWs, much closer balance on propensity scores. Remember to check the balance again. And one final love plot, this time with the IPW weights. This time, since we are no longer using an `ebalance` object, we do a slightly different set of arguments for `love.plot`. We pass it a formula, our entire data frame, a list of treatment status, that we are using weighting, our weights, and that the estimand is ATT:

```{r}
love.plot(bal.tab(balance_formula,
                  data = dat,
                  treat.list = treated,
                  method = "weighting",
                  weights = IPW,
                  estimand = "ATT"), theme=theme_bw())
```

Again, big improvement in balance. And now how do we use these weights to estimate an effect? Weighted least squares regression:

```{r}
#unweighted
summary(lm(educ ~ abd, data = dat))

#weighted by ipw
summary(lm(educ ~ abd, weight = IPW, data = dat))
```






